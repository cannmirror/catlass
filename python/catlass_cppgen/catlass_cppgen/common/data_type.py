from enum import Enum
from catlass_cppgen.common.typing import SupportedDataType
import torch


class DataType(Enum):
    """数据类型枚举，仅允许通过 from_dtype 构造"""

    UNDEFINED = "void"
    FLOAT = "float"
    FLOAT16 = "half"
    INT8 = "int8_t"
    INT32 = "int32_t"
    UINT8 = "uint8_t"
    INT16 = "int16_t"
    UINT16 = "uint16_t"
    UINT32 = "uint32_t"
    INT64 = "int64_t"
    UINT64 = "uint64_t"
    DOUBLE = "double"
    BOOL = "bool"
    STRING = "string"
    COMPLEX64 = "complex64"
    COMPLEX128 = "complex128"
    BF16 = "bfloat16_t"
    INT4 = "AscendC::int4_t"
    UINT1 = "uint1"
    COMPLEX32 = "complex32"
    HIFLOAT8 = "hi_float8"
    FLOAT8_E5M2 = "float8_e5m2"
    FLOAT8_E4M3FN = "float8_e4m3fn"
    FLOAT8_E8M0 = "float8_e8m0"
    FLOAT6_E3M2 = "float6_e3m2"
    FLOAT6_E2M3 = "float6_e2m3"
    FLOAT4_E2M1 = "float4_e2m1"
    FLOAT4_E1M2 = "float4_e1m2"

    @classmethod
    def from_dtype(cls, raw_dtype: SupportedDataType) -> "DataType":
        """仅通过from_dtype接口进行构造, 其余转换接口全部移除"""
        # 定义映射（不保留为类字段，简化为这里局部）
        torch_map = {
            torch.float32: cls.FLOAT,
            torch.float16: cls.FLOAT16,
            torch.int8: cls.INT8,
            torch.int32: cls.INT32,
            torch.uint8: cls.UINT8,
            torch.int16: cls.INT16,
            torch.int64: cls.INT64,
            torch.float64: cls.DOUBLE,
            torch.bool: cls.BOOL,
            torch.complex64: cls.COMPLEX64,
            torch.complex128: cls.COMPLEX128,
        }
        # torch别名
        if hasattr(torch, "bfloat16"):
            torch_map[torch.bfloat16] = cls.BF16
        if hasattr(torch, "float8_e5m2"):
            torch_map[torch.float8_e5m2] = cls.FLOAT8_E5M2
        if hasattr(torch, "float8_e4m3fn"):
            torch_map[torch.float8_e4m3fn] = cls.FLOAT8_E4M3FN

        torch_aliases = {
            torch.float: cls.FLOAT,
            torch.half: cls.FLOAT16,
            torch.double: cls.DOUBLE,
            torch.short: cls.INT16,
            torch.int: cls.INT32,
            torch.long: cls.INT64,
        }
        torch_map.update(torch_aliases)

        # direct torch match
        if isinstance(raw_dtype, torch.dtype):
            if raw_dtype in torch_map:
                return torch_map[raw_dtype]
            if str(raw_dtype) == "torch.float8_e5m2":
                return cls.FLOAT8_E5M2
            if str(raw_dtype) == "torch.float8_e4m3fn":
                return cls.FLOAT8_E4M3FN
            # 如果传入的是 torch.dtype 但不在映射中，返回 UNDEFINED
            return cls.UNDEFINED

        # 如果传入的是其他类型（非 torch.dtype），返回 UNDEFINED
        return cls.UNDEFINED


def get_default_accumulator(data_type_A: DataType, data_type_B: DataType) -> DataType:
    """获取默认的累加器数据类型"""
    assert data_type_A == data_type_B

    accumulator_map = {
        (DataType.FLOAT16, DataType.FLOAT16): DataType.FLOAT,
        (DataType.FLOAT, DataType.FLOAT16): DataType.FLOAT,
        (DataType.BF16, DataType.BF16): DataType.FLOAT,
        (DataType.INT8, DataType.INT8): DataType.INT32,
    }

    return accumulator_map.get((data_type_A, data_type_B), data_type_A)
